# Feature extraction parameters
feature:
  n_mels: 48           # Reduced from 64
  frames: 4            # Reduced from 5
  n_fft: 1024          # Keep as is
  hop_length: 1024     # Doubled from 512
  stride: 4 
  power: 2.0
  augmentation:
    enabled: true
    max_mask_freq: 10
    max_mask_time: 10
    n_freq_masks: 2
    n_time_masks: 2
    noise_level: 0.01

# Fit algorithm parameters
fit:
  compile:
    optimizer: "adam"
    learning_rate: 0.001  # Adam optimizer learning rate
    loss: "binary_crossentropy"
    metrics: ["accuracy"]
    weighted_metrics: ["accuracy"]
  epochs: 150
  batch_size: 512
  shuffle: True
  validation_split: 0.1
  verbose: 1
  early_stopping:
    enabled: true
    monitor: "val_loss"
    patience: 10
    min_delta: 0.001
    restore_best_weights: true
  weight_factor: 1.5  # For non-problematic IDs
  weighted_machine_ids: []  # Will handle id_00 and id_04 explicitly in code
  apply_sample_weights: true  # Enable sample weighting
  # Special case weights for problematic machine IDs
  special_case_weights:
    fan_id_00: 2.0
    fan_id_04: 2.0

# Model architecture parameters
model:
  architecture:
    depth: 4
    width: 128
    bottleneck: 32
    activation: "sigmoid"
    dropout: 0.2
    batch_norm: true
    residual: true
    weight_decay: 0.0001  # L2 regularization weight decay
  loss: "binary_crossentropy"
  normalization_method: "minmax"  # Options: "minmax", "zscore", "log"
  threshold_optimization: true

# Dataset generation parameters
dataset:
  split_ratio: [0.8, 0.1, 0.1]  # [train, validation, test]
  file_extension: "wav"
  default_prediction: 0.5  # Default value for error cases

# Visualization parameters
visualization:
  figure_size: [30, 20]
  history_plots: ["loss", "accuracy"]

# Directory paths
base_directory: "./dataset"
pickle_directory: "./pickle/pickle_fnn"
model_directory: "./model/model_fnn"
result_directory: "./result/result_fnn"
result_file: "result_fnn.yaml"

# Logging parameters
logging:
  level: "DEBUG"
  file: "./logs/log_fnn/baseline_fnn.log"