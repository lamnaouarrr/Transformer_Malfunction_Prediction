# Feature extraction parameters
feature:
  n_mels: 48           # Reduced from 64
  frames: 4            # Reduced from 5
  n_fft: 1024          # Keep as is
  hop_length: 1024     # Doubled from 512
  stride: 4 
  power: 2.0
  sr: 16000
  augmentation:
    enabled: true
    max_mask_freq: 10
    max_mask_time: 10
    n_freq_masks: 2
    n_time_masks: 2
    noise_level: 0.01

# Fit algorithm parameters
fit:
  compile:
    optimizer: "adam"
    learning_rate: 0.0001  # Lower learning rate for transformer
    loss: "binary_crossentropy"
    metrics: ["accuracy"]
    weighted_metrics: ["accuracy"]
  epochs: 150
  batch_size: 128
  shuffle: True
  validation_split: 0.1
  verbose: 1
  early_stopping:
    enabled: true
    monitor: "val_loss"
    patience: 10
    min_delta: 0.001
    restore_best_weights: true
  weight_factor: 1.5  # For non-problematic IDs
  weighted_machine_ids: []  # Will handle id_00 and id_04 explicitly in code
  apply_sample_weights: true  # Enable sample weighting
  special_case_weights: # Special case weights for problematic machine IDs
    fan_id_00: 2.0
    fan_id_04: 2.0
  lr_scheduler:
    enabled: true
    monitor: "val_loss"
    factor: 0.1
    patience: 5
    min_delta: 0.001
    cooldown: 2
    min_lr: 0.00000001
  checkpointing:
    enabled: true
    monitor: "val_accuracy"
    mode: "max"
    save_best_only: true

# Training optimizations
training:
  mixed_precision: true
  xla_acceleration: true
  gradient_accumulation_steps: 4  # Add gradient accumulation for larger effective batch size

# Enhanced transformer model settings
model:
  architecture:
    transformer:
      num_heads: 8
      dim_feedforward: 512
      num_encoder_layers: 4
      positional_encoding: true
      use_pretrained: true
      pretrained_model: "google/vit-base-patch16-224"
      patch_size: 16
      attention_dropout: 0.1
      # New parameters
      attention_type: "efficient"  # Options: "standard", "efficient", "linear"
      pos_encoding_type: "sinusoidal"  # Options: "sinusoidal", "learned", "alibi", "rotary"
      layer_norm_epsilon: 1.0e-6
      activation_fn: "gelu"  # Options: "gelu", "relu", "swish"
      ff_dim_multiplier: 4
      enable_rotary: false


# Dataset generation parameters
dataset:
  split_ratio: [0.8, 0.1, 0.1]  # [train, validation, test]
  file_extension: "wav"
  default_prediction: 0.5  # Default value for error cases

# Visualization parameters
visualization:
  figure_size: [30, 20]
  history_plots: ["loss", "accuracy"]

# Directory paths
base_directory: "./dataset"
pickle_directory: "./pickle/pickle_AST"
model_directory: "./model/AST"
result_directory: "./result/result_AST"
result_file: "result_AST.yaml"

# Logging parameters
logging:
  level: "DEBUG"
  file: "./logs/log_AST/baseline_AST.log"